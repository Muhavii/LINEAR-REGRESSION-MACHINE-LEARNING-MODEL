{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac2f1f6-471b-46da-846a-d4ac9e378b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Model Accuracy: 90.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Hate       1.00      0.80      0.89         5\n",
      "    Non-Hate       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.92      0.90      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Kiswahili hate speech dataset\n",
    "data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"Nakuambia usiende mbali, wewe ni mchafu\",\n",
    "        \"Habari yako, natumai uko salama\",\n",
    "        \"Ukiwa huna haja ya kuendesha kama hiyo\",\n",
    "        \"Leo ni siku nzuri kwa kila mtu\",\n",
    "        \"Utakuwa duni zaidi ikiwa utaendelea hivyo\",\n",
    "        \"Mimi naahidi kukusaidia kukamilisha kazi yako\",\n",
    "        \"Wewe ni kipofu, hauna akili\",\n",
    "        \"Tafadhali njoo kwenye mkutano kesho\",\n",
    "        \"Umechafuka kabisa, hakuna muhimu yoyote\",\n",
    "        \"Tunashukuru kwa msaada wako mkubwa\",\n",
    "        \"Unapenda kuwa mpumbavu kila wakati\",\n",
    "        \"Hakuna tatizo, tuko pamoja katika hili\",\n",
    "        \"Wewe ni batili, usirudi tena\",\n",
    "        \"Nitakuombea afya njema na furaha\",\n",
    "        \"Sina imani na wewe, wewe ni dududu\",\n",
    "        \"Tunapenda kushirikiana na wewe\",\n",
    "        \"Wewe ni mpimbaji wa jamii yetu\",\n",
    "        \"Asante kwa kuchukua muda kuzungumza nasi\",\n",
    "        \"Hao ni watu wakuu wa utovu\",\n",
    "        \"Hongera kwa mafanikio yako leo\",\n",
    "        \"Wewe ni dhuluma, utakuwa duni sana\",\n",
    "        \"Natumai una siku njema\",\n",
    "        \"Umeonyesha hofu, usirudi tena\",\n",
    "        \"Tuko pamoja katika hatua zote\",\n",
    "        \"Wewe ni mfupi sana akili\",\n",
    "        \"Nakupenda na ninathamini urafiki wetu\",\n",
    "        \"Umevunjika moyo, usijaribu tena\",\n",
    "        \"Tuna furaha kukuona leo\",\n",
    "        \"Wewe ni kipumbavu, hakuna hatima\",\n",
    "        \"Karibu sana, tunakutegemea\",\n",
    "        \"Umejizoea kukosea, usirudi tena\",\n",
    "        \"Tunathamini mchango wako kwa jamii\",\n",
    "        \"Wewe ni mjinga, usifanye hivyo tena\",\n",
    "        \"Hongera kwa mafanikio yako\",\n",
    "        \"Utakuwa hatia ikiwa utaendelea\",\n",
    "        \"Tunapenda msaada wako\",\n",
    "        \"Wewe ni hatari kwa jamii yetu\",\n",
    "        \"Asante kwa msaada wako\",\n",
    "        \"Usifanya kazi hiyo, wewe ni mjinga\",\n",
    "        \"Tunashukuru kwa kujitolea kwako\",\n",
    "        \"Wewe ni mchafu, usiende mbele\",\n",
    "        \"Tunathamini ushirikiano wako\",\n",
    "        \"Wewe ni duni, hatia yako\",\n",
    "        \"Asante kwa kukusaidia\",\n",
    "        \"Wewe ni kipofu, usibale tena\",\n",
    "        \"Tunapenda kushirikiana na wewe\",\n",
    "        \"Wewe ni kipumbavu, usifanye hivyo\",\n",
    "        \"Tunathamini mchango wako\",\n",
    "    ],\n",
    "    'label': [\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "        \"Hate\",\n",
    "        \"Non-Hate\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "# 2. Data Preprocessing\n",
    "\n",
    "# Downloading NLTK stopwords \n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Perform basic text cleaning: lowercase, remove punctuation, and numbers.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Converting to lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # Removing numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Removing punctuation\n",
    "    text = text.strip()  # Removing leading whitespace\n",
    "    return text\n",
    "\n",
    "def remove_stopwords_func(text):\n",
    "    \"\"\"\n",
    "    Remove Kiswahili stopwords from the text.\n",
    "    \"\"\"\n",
    "    # Define a comprehensive Kiswahili stopword list\n",
    "    kiswahili_stopwords = set([\n",
    "        'ni', 'na', 'kwa', 'ya', 'yao', 'yake', 'yako', 'yako', 'sawa',\n",
    "        'hakuna', 'kama', 'kufanya', 'hivi', 'hivyo', 'kwenye', 'na', 'kwa',\n",
    "        'tuko', 'tuna', 'tunapenda', 'tunathamini', 'hakuna', 'sana',\n",
    "        'natumai', 'tunafuraha', 'nakupenda', 'na', 'mimi', 'wewe',\n",
    "        'usirudi', 'uwe', 'unapenda', 'uweo', 'utakuwa', 'tuko',\n",
    "        'tuchukulie', 'usijaribu', 'asi', 'alipo', 'mwenye', 'iliyokuwa',\n",
    "        'aliko', 'yuko', 'tu', 'tuwe', 'tuja', 'tuko', 'twende', 'wa',\n",
    "        'wa', 'wako', 'wetu', 'wake', 'wao', 'wala', 'wanangu', 'wake',\n",
    "        'wao', 'wao', 'wa', 'wao', 'wa', 'tu', 'tu', 'wako'\n",
    "    ])\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word not in kiswahili_stopwords]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Applying cleaning\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Removing stopwords\n",
    "data['cleaned_text'] = data['cleaned_text'].apply(remove_stopwords_func)\n",
    "\n",
    "# 3. Feature Extraction with N-grams\n",
    "\n",
    "X = data['cleaned_text']\n",
    "y = data['label']\n",
    "\n",
    "# Splitting the dataset (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Initializing TF-IDF Vectorizer with bigrams\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# 4. Model Training with SVM and Hyperparameter Tuning\n",
    "\n",
    "# Initializing the classifier\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Defining hyperparameters for Grid Search\n",
    "parameters = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Initializing GridSearchCV\n",
    "grid_search = GridSearchCV(svm, parameters, cv=5, scoring='accuracy')\n",
    "\n",
    "# Training the model with Grid Search\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best estimator after Grid Search\n",
    "best_svm = grid_search.best_estimator_\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = best_svm.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# 5. GUI Interface\n",
    "\n",
    "def classify_text():\n",
    "    \"\"\"\n",
    "    Classify the input text and display the result.\n",
    "    \"\"\"\n",
    "    input_text = entry.get()\n",
    "    if not input_text.strip():\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter some text.\")\n",
    "        return\n",
    "    \n",
    "    # Preprocessing the input text\n",
    "    cleaned_input = clean_text(input_text)\n",
    "    cleaned_input = remove_stopwords_func(cleaned_input)\n",
    "    \n",
    "    # Vectorizing the input text\n",
    "    input_vector = vectorizer.transform([cleaned_input])\n",
    "    \n",
    "    # Predicting the label\n",
    "    prediction = best_svm.predict(input_vector)[0]\n",
    "    \n",
    "    # Displaying the result\n",
    "    if prediction == 'Hate':\n",
    "        messagebox.showinfo(\"Result\", \"The text is identified as HATE SPEECH.\")\n",
    "    else:\n",
    "        messagebox.showinfo(\"Result\", \"The text is identified as NON-HATE SPEECH.\")\n",
    "\n",
    "# Initializing Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Kiswahili Hate Speech Detector\")\n",
    "root.geometry(\"500x200\")\n",
    "root.resizable(False, False)\n",
    "\n",
    "# Label\n",
    "label = tk.Label(root, text=\"Enter Kiswahili text:\", font=(\"Helvetica\", 14))\n",
    "label.pack(pady=10)\n",
    "\n",
    "# Text Entry (Single-line)\n",
    "entry = tk.Entry(root, width=60, font=(\"Helvetica\", 12))\n",
    "entry.pack(pady=5)\n",
    "\n",
    "# Classifying Button\n",
    "button = tk.Button(root, text=\"Classify\", command=classify_text, font=(\"Helvetica\", 12), bg=\"#4CAF50\", fg=\"white\")\n",
    "button.pack(pady=20)\n",
    "\n",
    "# Running the application\n",
    "root.mainloop()\n",
    "\n",
    "# This was all done in a jupyter notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4978d0-adbe-41f5-9615-6e98d8c71203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
